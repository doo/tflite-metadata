# automatically generated by the FlatBuffers compiler, do not modify

# namespace: tflite

import flatbuffers
from flatbuffers.compat import import_numpy
np = import_numpy()

class RegexTokenizerOptions(object):
    __slots__ = ['_tab']

    @classmethod
    def GetRootAs(cls, buf, offset=0):
        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)
        x = RegexTokenizerOptions()
        x.Init(buf, n + offset)
        return x

    @classmethod
    def GetRootAsRegexTokenizerOptions(cls, buf, offset=0):
        """This method is deprecated. Please switch to GetRootAs."""
        return cls.GetRootAs(buf, offset)
    @classmethod
    def RegexTokenizerOptionsBufferHasIdentifier(cls, buf, offset, size_prefixed=False):
        return flatbuffers.util.BufferHasIdentifier(buf, offset, b"\x4D\x30\x30\x31", size_prefixed=size_prefixed)

    # RegexTokenizerOptions
    def Init(self, buf, pos):
        self._tab = flatbuffers.table.Table(buf, pos)

    # RegexTokenizerOptions
    def DelimRegexPattern(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))
        if o != 0:
            return self._tab.String(o + self._tab.Pos)
        return None

    # RegexTokenizerOptions
    def VocabFile(self, j):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        if o != 0:
            x = self._tab.Vector(o)
            x += flatbuffers.number_types.UOffsetTFlags.py_type(j) * 4
            x = self._tab.Indirect(x)
            from tflite.AssociatedFile import AssociatedFile
            obj = AssociatedFile()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

    # RegexTokenizerOptions
    def VocabFileLength(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        if o != 0:
            return self._tab.VectorLen(o)
        return 0

    # RegexTokenizerOptions
    def VocabFileIsNone(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        return o == 0

def RegexTokenizerOptionsStart(builder): builder.StartObject(2)
def Start(builder):
    return RegexTokenizerOptionsStart(builder)
def RegexTokenizerOptionsAddDelimRegexPattern(builder, delimRegexPattern): builder.PrependUOffsetTRelativeSlot(0, flatbuffers.number_types.UOffsetTFlags.py_type(delimRegexPattern), 0)
def AddDelimRegexPattern(builder, delimRegexPattern):
    return RegexTokenizerOptionsAddDelimRegexPattern(builder, delimRegexPattern)
def RegexTokenizerOptionsAddVocabFile(builder, vocabFile): builder.PrependUOffsetTRelativeSlot(1, flatbuffers.number_types.UOffsetTFlags.py_type(vocabFile), 0)
def AddVocabFile(builder, vocabFile):
    return RegexTokenizerOptionsAddVocabFile(builder, vocabFile)
def RegexTokenizerOptionsStartVocabFileVector(builder, numElems): return builder.StartVector(4, numElems, 4)
def StartVocabFileVector(builder, numElems):
    return RegexTokenizerOptionsStartVocabFileVector(builder, numElems)
def RegexTokenizerOptionsEnd(builder): return builder.EndObject()
def End(builder):
    return RegexTokenizerOptionsEnd(builder)