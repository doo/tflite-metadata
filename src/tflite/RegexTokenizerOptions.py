# automatically generated by the FlatBuffers compiler, do not modify

# namespace: tflite

import flatbuffers
from flatbuffers.compat import import_numpy

np = import_numpy()


class RegexTokenizerOptions(object):
    __slots__ = ["_tab"]

    @classmethod
    def GetRootAs(cls, buf, offset=0):
        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)
        x = RegexTokenizerOptions()
        x.Init(buf, n + offset)
        return x

    @classmethod
    def GetRootAsRegexTokenizerOptions(cls, buf, offset=0):
        """This method is deprecated. Please switch to GetRootAs."""
        return cls.GetRootAs(buf, offset)

    @classmethod
    def RegexTokenizerOptionsBufferHasIdentifier(cls, buf, offset, size_prefixed=False):
        return flatbuffers.util.BufferHasIdentifier(
            buf, offset, b"\x4D\x30\x30\x31", size_prefixed=size_prefixed
        )

    # RegexTokenizerOptions
    def Init(self, buf, pos):
        self._tab = flatbuffers.table.Table(buf, pos)

    # RegexTokenizerOptions
    def DelimRegexPattern(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))
        if o != 0:
            return self._tab.String(o + self._tab.Pos)
        return None

    # RegexTokenizerOptions
    def VocabFile(self, j):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        if o != 0:
            x = self._tab.Vector(o)
            x += flatbuffers.number_types.UOffsetTFlags.py_type(j) * 4
            x = self._tab.Indirect(x)
            from tflite.AssociatedFile import AssociatedFile

            obj = AssociatedFile()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

    # RegexTokenizerOptions
    def VocabFileLength(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        if o != 0:
            return self._tab.VectorLen(o)
        return 0

    # RegexTokenizerOptions
    def VocabFileIsNone(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        return o == 0


def RegexTokenizerOptionsStart(builder):
    builder.StartObject(2)


def Start(builder):
    return RegexTokenizerOptionsStart(builder)


def RegexTokenizerOptionsAddDelimRegexPattern(builder, delimRegexPattern):
    builder.PrependUOffsetTRelativeSlot(
        0, flatbuffers.number_types.UOffsetTFlags.py_type(delimRegexPattern), 0
    )


def AddDelimRegexPattern(builder, delimRegexPattern):
    return RegexTokenizerOptionsAddDelimRegexPattern(builder, delimRegexPattern)


def RegexTokenizerOptionsAddVocabFile(builder, vocabFile):
    builder.PrependUOffsetTRelativeSlot(
        1, flatbuffers.number_types.UOffsetTFlags.py_type(vocabFile), 0
    )


def AddVocabFile(builder, vocabFile):
    return RegexTokenizerOptionsAddVocabFile(builder, vocabFile)


def RegexTokenizerOptionsStartVocabFileVector(builder, numElems):
    return builder.StartVector(4, numElems, 4)


def StartVocabFileVector(builder, numElems):
    return RegexTokenizerOptionsStartVocabFileVector(builder, numElems)


def RegexTokenizerOptionsEnd(builder):
    return builder.EndObject()


def End(builder):
    return RegexTokenizerOptionsEnd(builder)


import tflite.AssociatedFile

try:
    pass
except:
    pass


class RegexTokenizerOptionsT(object):

    # RegexTokenizerOptionsT
    def __init__(self):
        self.delimRegexPattern = None  # type: str
        self.vocabFile = None  # type: List[tflite.AssociatedFile.AssociatedFileT]

    @classmethod
    def InitFromBuf(cls, buf, pos):
        regexTokenizerOptions = RegexTokenizerOptions()
        regexTokenizerOptions.Init(buf, pos)
        return cls.InitFromObj(regexTokenizerOptions)

    @classmethod
    def InitFromPackedBuf(cls, buf, pos=0):
        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, pos)
        return cls.InitFromBuf(buf, pos + n)

    @classmethod
    def InitFromObj(cls, regexTokenizerOptions):
        x = RegexTokenizerOptionsT()
        x._UnPack(regexTokenizerOptions)
        return x

    # RegexTokenizerOptionsT
    def _UnPack(self, regexTokenizerOptions):
        if regexTokenizerOptions is None:
            return
        self.delimRegexPattern = regexTokenizerOptions.DelimRegexPattern()
        if not regexTokenizerOptions.VocabFileIsNone():
            self.vocabFile = []
            for i in range(regexTokenizerOptions.VocabFileLength()):
                if regexTokenizerOptions.VocabFile(i) is None:
                    self.vocabFile.append(None)
                else:
                    associatedFile_ = tflite.AssociatedFile.AssociatedFileT.InitFromObj(
                        regexTokenizerOptions.VocabFile(i)
                    )
                    self.vocabFile.append(associatedFile_)

    # RegexTokenizerOptionsT
    def Pack(self, builder):
        if self.delimRegexPattern is not None:
            delimRegexPattern = builder.CreateString(self.delimRegexPattern)
        if self.vocabFile is not None:
            vocabFilelist = []
            for i in range(len(self.vocabFile)):
                vocabFilelist.append(self.vocabFile[i].Pack(builder))
            RegexTokenizerOptionsStartVocabFileVector(builder, len(self.vocabFile))
            for i in reversed(range(len(self.vocabFile))):
                builder.PrependUOffsetTRelative(vocabFilelist[i])
            vocabFile = builder.EndVector()
        RegexTokenizerOptionsStart(builder)
        if self.delimRegexPattern is not None:
            RegexTokenizerOptionsAddDelimRegexPattern(builder, delimRegexPattern)
        if self.vocabFile is not None:
            RegexTokenizerOptionsAddVocabFile(builder, vocabFile)
        regexTokenizerOptions = RegexTokenizerOptionsEnd(builder)
        return regexTokenizerOptions
