# automatically generated by the FlatBuffers compiler, do not modify

# namespace: tflite

import flatbuffers
from flatbuffers.compat import import_numpy
np = import_numpy()

class SentencePieceTokenizerOptions(object):
    __slots__ = ['_tab']

    @classmethod
    def GetRootAs(cls, buf, offset=0):
        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)
        x = SentencePieceTokenizerOptions()
        x.Init(buf, n + offset)
        return x

    @classmethod
    def GetRootAsSentencePieceTokenizerOptions(cls, buf, offset=0):
        """This method is deprecated. Please switch to GetRootAs."""
        return cls.GetRootAs(buf, offset)
    @classmethod
    def SentencePieceTokenizerOptionsBufferHasIdentifier(cls, buf, offset, size_prefixed=False):
        return flatbuffers.util.BufferHasIdentifier(buf, offset, b"\x4D\x30\x30\x31", size_prefixed=size_prefixed)

    # SentencePieceTokenizerOptions
    def Init(self, buf, pos):
        self._tab = flatbuffers.table.Table(buf, pos)

    # SentencePieceTokenizerOptions
    def SentencePieceModel(self, j):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))
        if o != 0:
            x = self._tab.Vector(o)
            x += flatbuffers.number_types.UOffsetTFlags.py_type(j) * 4
            x = self._tab.Indirect(x)
            from tflite.AssociatedFile import AssociatedFile
            obj = AssociatedFile()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

    # SentencePieceTokenizerOptions
    def SentencePieceModelLength(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))
        if o != 0:
            return self._tab.VectorLen(o)
        return 0

    # SentencePieceTokenizerOptions
    def SentencePieceModelIsNone(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))
        return o == 0

    # SentencePieceTokenizerOptions
    def VocabFile(self, j):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        if o != 0:
            x = self._tab.Vector(o)
            x += flatbuffers.number_types.UOffsetTFlags.py_type(j) * 4
            x = self._tab.Indirect(x)
            from tflite.AssociatedFile import AssociatedFile
            obj = AssociatedFile()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

    # SentencePieceTokenizerOptions
    def VocabFileLength(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        if o != 0:
            return self._tab.VectorLen(o)
        return 0

    # SentencePieceTokenizerOptions
    def VocabFileIsNone(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        return o == 0

def SentencePieceTokenizerOptionsStart(builder): builder.StartObject(2)
def Start(builder):
    return SentencePieceTokenizerOptionsStart(builder)
def SentencePieceTokenizerOptionsAddSentencePieceModel(builder, sentencePieceModel): builder.PrependUOffsetTRelativeSlot(0, flatbuffers.number_types.UOffsetTFlags.py_type(sentencePieceModel), 0)
def AddSentencePieceModel(builder, sentencePieceModel):
    return SentencePieceTokenizerOptionsAddSentencePieceModel(builder, sentencePieceModel)
def SentencePieceTokenizerOptionsStartSentencePieceModelVector(builder, numElems): return builder.StartVector(4, numElems, 4)
def StartSentencePieceModelVector(builder, numElems):
    return SentencePieceTokenizerOptionsStartSentencePieceModelVector(builder, numElems)
def SentencePieceTokenizerOptionsAddVocabFile(builder, vocabFile): builder.PrependUOffsetTRelativeSlot(1, flatbuffers.number_types.UOffsetTFlags.py_type(vocabFile), 0)
def AddVocabFile(builder, vocabFile):
    return SentencePieceTokenizerOptionsAddVocabFile(builder, vocabFile)
def SentencePieceTokenizerOptionsStartVocabFileVector(builder, numElems): return builder.StartVector(4, numElems, 4)
def StartVocabFileVector(builder, numElems):
    return SentencePieceTokenizerOptionsStartVocabFileVector(builder, numElems)
def SentencePieceTokenizerOptionsEnd(builder): return builder.EndObject()
def End(builder):
    return SentencePieceTokenizerOptionsEnd(builder)
import tflite.AssociatedFile
try:
    from typing import List
except:
    pass

class SentencePieceTokenizerOptionsT(object):

    # SentencePieceTokenizerOptionsT
    def __init__(self):
        self.sentencePieceModel = None  # type: List[tflite.AssociatedFile.AssociatedFileT]
        self.vocabFile = None  # type: List[tflite.AssociatedFile.AssociatedFileT]

    @classmethod
    def InitFromBuf(cls, buf, pos):
        sentencePieceTokenizerOptions = SentencePieceTokenizerOptions()
        sentencePieceTokenizerOptions.Init(buf, pos)
        return cls.InitFromObj(sentencePieceTokenizerOptions)

    @classmethod
    def InitFromPackedBuf(cls, buf, pos=0):
        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, pos)
        return cls.InitFromBuf(buf, pos+n)

    @classmethod
    def InitFromObj(cls, sentencePieceTokenizerOptions):
        x = SentencePieceTokenizerOptionsT()
        x._UnPack(sentencePieceTokenizerOptions)
        return x

    # SentencePieceTokenizerOptionsT
    def _UnPack(self, sentencePieceTokenizerOptions):
        if sentencePieceTokenizerOptions is None:
            return
        if not sentencePieceTokenizerOptions.SentencePieceModelIsNone():
            self.sentencePieceModel = []
            for i in range(sentencePieceTokenizerOptions.SentencePieceModelLength()):
                if sentencePieceTokenizerOptions.SentencePieceModel(i) is None:
                    self.sentencePieceModel.append(None)
                else:
                    associatedFile_ = tflite.AssociatedFile.AssociatedFileT.InitFromObj(sentencePieceTokenizerOptions.SentencePieceModel(i))
                    self.sentencePieceModel.append(associatedFile_)
        if not sentencePieceTokenizerOptions.VocabFileIsNone():
            self.vocabFile = []
            for i in range(sentencePieceTokenizerOptions.VocabFileLength()):
                if sentencePieceTokenizerOptions.VocabFile(i) is None:
                    self.vocabFile.append(None)
                else:
                    associatedFile_ = tflite.AssociatedFile.AssociatedFileT.InitFromObj(sentencePieceTokenizerOptions.VocabFile(i))
                    self.vocabFile.append(associatedFile_)

    # SentencePieceTokenizerOptionsT
    def Pack(self, builder):
        if self.sentencePieceModel is not None:
            sentencePieceModellist = []
            for i in range(len(self.sentencePieceModel)):
                sentencePieceModellist.append(self.sentencePieceModel[i].Pack(builder))
            SentencePieceTokenizerOptionsStartSentencePieceModelVector(builder, len(self.sentencePieceModel))
            for i in reversed(range(len(self.sentencePieceModel))):
                builder.PrependUOffsetTRelative(sentencePieceModellist[i])
            sentencePieceModel = builder.EndVector()
        if self.vocabFile is not None:
            vocabFilelist = []
            for i in range(len(self.vocabFile)):
                vocabFilelist.append(self.vocabFile[i].Pack(builder))
            SentencePieceTokenizerOptionsStartVocabFileVector(builder, len(self.vocabFile))
            for i in reversed(range(len(self.vocabFile))):
                builder.PrependUOffsetTRelative(vocabFilelist[i])
            vocabFile = builder.EndVector()
        SentencePieceTokenizerOptionsStart(builder)
        if self.sentencePieceModel is not None:
            SentencePieceTokenizerOptionsAddSentencePieceModel(builder, sentencePieceModel)
        if self.vocabFile is not None:
            SentencePieceTokenizerOptionsAddVocabFile(builder, vocabFile)
        sentencePieceTokenizerOptions = SentencePieceTokenizerOptionsEnd(builder)
        return sentencePieceTokenizerOptions
